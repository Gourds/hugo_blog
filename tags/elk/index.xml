<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ELK on Gourds</title>
    <link>https://blog.gourds.site/tags/elk/</link>
    <description>Recent content in ELK on Gourds</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 01 Aug 2018 12:11:16 +0000</lastBuildDate><atom:link href="https://blog.gourds.site/tags/elk/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Elasticsearch使用curator管理index</title>
      <link>https://blog.gourds.site/post/es%E4%BD%BF%E7%94%A8curator%E7%AE%A1%E7%90%86index/</link>
      <pubDate>Wed, 01 Aug 2018 12:11:16 +0000</pubDate>
      
      <guid>https://blog.gourds.site/post/es%E4%BD%BF%E7%94%A8curator%E7%AE%A1%E7%90%86index/</guid>
      <description>&lt;p&gt;有个管理ES index的需求，感觉使用curl调用HTTP接口很不方便也不是很科学。在Github上一查，果然有官方提供的工具&lt;code&gt;curator&lt;/code&gt;，这个工具不仅仅满足了我简单管理的需要（索引的关闭、打开、段合并、删除等），也为以后的扩展提供了新的解决方案（支持磁盘占用触发）,非常不错。以下记录我的调研测试过程。另外补充一句&lt;code&gt;curator&lt;/code&gt;的官方文档十分完备，如喜欢直接阅读官方文档可以直接跳到本文底部，那里有官方文档链接。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fluentd使用中遇到的丢数据问题</title>
      <link>https://blog.gourds.site/post/fluentd%E4%BD%BF%E7%94%A8%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%A2%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98/</link>
      <pubDate>Wed, 11 Apr 2018 17:52:00 +0000</pubDate>
      
      <guid>https://blog.gourds.site/post/fluentd%E4%BD%BF%E7%94%A8%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%A2%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98/</guid>
      <description>&lt;p&gt;目前遇到的问题主要有3个：两个关于buffer，一个关于connection。下面具体说描述下问题的详细信息及目前我采取的解决措施。先交代下我这里使用的Td-agent架构如下，PS（方便起见以下均将Td-agent简化为TD，关于TD和Fluentd的关系移步我的另一篇&lt;a href=&#34;http://arvon.top/2018/02/23/Td-agent%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/&#34;&gt;Blog&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;需要注意： 这里的缓存Buffer设置对0.14.21版本测试生效，亲测0.12.20不生效，具体可到&lt;a href=&#34;https://docs.fluentd.org/v1.0/articles/quickstart&#34;&gt;【Fluentd官网】&lt;/a&gt;获取支持。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;graph LR;
	  A(Td-client)--&amp;gt;F(Td-forward)
    B(Td-client)--&amp;gt;F(Td-forward)
    F--&amp;gt;E(Elasticsearch cluster)
    E--&amp;gt;K(Kibana)
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Kibana使用sentinl报警实践</title>
      <link>https://blog.gourds.site/post/kibana%E4%BD%BF%E7%94%A8sentinl%E6%8A%A5%E8%AD%A6%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 15 Mar 2018 13:13:45 +0000</pubDate>
      
      <guid>https://blog.gourds.site/post/kibana%E4%BD%BF%E7%94%A8sentinl%E6%8A%A5%E8%AD%A6%E5%AE%9E%E8%B7%B5/</guid>
      <description>&lt;p&gt;&lt;strong&gt;背景介绍：&lt;/strong&gt;
对于Kibana的一些数据我们有时候是想要对某些字段进行持续关注的，这时候通过报警的手段就可以大幅提升对这些信息状态了解的及时性及可靠性。使用&lt;a href=&#34;https://github.com/sirensolutions/sentinl&#34;&gt;Sentinl这个kibana开源插件&lt;/a&gt;，就可以帮助我们实现这个功能。这里记录一下我的实践过程，主要是对一些业务数据某些字段进行监控报警。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>关于Fluentd使用中filter及ES插件的问题记录</title>
      <link>https://blog.gourds.site/post/%E5%85%B3%E4%BA%8Efluentd%E4%BD%BF%E7%94%A8%E4%B8%ADfilter%E5%8F%8Aes%E6%8F%92%E4%BB%B6%E7%9A%84%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Thu, 01 Mar 2018 11:00:00 +0000</pubDate>
      
      <guid>https://blog.gourds.site/post/%E5%85%B3%E4%BA%8Efluentd%E4%BD%BF%E7%94%A8%E4%B8%ADfilter%E5%8F%8Aes%E6%8F%92%E4%BB%B6%E7%9A%84%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;p&gt;**背景介绍：**线上需求将业务log数据清洗后导入kibana，原始log也要一同导入，从服务直接输出两份log肯定是不合理的，所以考虑从fluentd收集的时候进行处理，先将原始数据复制为2份，然后一份直接导入kibana，另一份通过fluentd的filter进行过滤筛选后导入kibana。其中filter遇到无法筛选nested类型数据的问题，升级版本后并更改写法后解决；升级后导致ES的index无法按原来的方法命名的问题，通过更换ES插件解决，具体见以下记录。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;测试环境：
OS: Amazon Linux AMI release 2015.03
Fluentd: td-agent 0.12.20&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Td-agent配置说明</title>
      <link>https://blog.gourds.site/post/td-agent%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/</link>
      <pubDate>Fri, 23 Feb 2018 21:00:00 +0000</pubDate>
      
      <guid>https://blog.gourds.site/post/td-agent%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/</guid>
      <description>&lt;p&gt;&lt;strong&gt;简介：&lt;/strong&gt;
生产环境并没有使用传统ELK,而是使用tdagent来代替Logstash作日志收集。
关于td-agent和Fluentd的关系可以引用&lt;a href=&#34;https://www.fluentd.org/faqs&#34;&gt;官网的描述&lt;/a&gt;：&lt;code&gt;&amp;quot;In one word, td-agent is a stable distribution package of Fluentd.&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;update：2017-05-20 初次修改&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;一般架构&#34;&gt;一般架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;http://img.arvon.top:80/images/2019/08/12/20170911-fluentd-1.jpg&#34; alt=&#34;fluentd-1&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Elasticsearch默认fields1000报错解决</title>
      <link>https://blog.gourds.site/post/elasticsearch%E9%BB%98%E8%AE%A4fields1000%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/</link>
      <pubDate>Fri, 24 Nov 2017 16:11:16 +0000</pubDate>
      
      <guid>https://blog.gourds.site/post/elasticsearch%E9%BB%98%E8%AE%A4fields1000%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/</guid>
      <description>&lt;p&gt;**背景：**由于日志输出调整，ES出现了很多如下的报错，这个issue可以在&lt;a href=&#34;https://github.com/elastic/elasticsearch/pull/17357&#34;&gt;这个github地址找到&lt;/a&gt;,另外还有&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/5.0/indices-update-settings.html&#34;&gt;5.0版本关于这个问题的说明&lt;/a&gt;。
我的ES版本为：5.0.0(直接curl yourip:9200就可以看到)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is to prevent mapping explosion when dynamic keys such as UUID are used as field names. index.mapping.total_fields.limit specifies the total number of fields an index can have. An exception will be thrown when the limit is reached. The default limit is 1000. Value 0 means no limit. This setting is runtime adjustable
&lt;strong&gt;&amp;ndash; &amp;ndash; &amp;ndash; 以上摘自&lt;/strong&gt;yanjunh对于该issue的答复&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>关于Kafka分布式消息队列</title>
      <link>https://blog.gourds.site/post/%E5%85%B3%E4%BA%8Ekafka%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link>
      <pubDate>Sun, 05 Nov 2017 21:00:00 +0000</pubDate>
      
      <guid>https://blog.gourds.site/post/%E5%85%B3%E4%BA%8Ekafka%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid>
      <description>&lt;p&gt;&lt;strong&gt;背景:&lt;/strong&gt; 直接使用EFK进行日志收集，在大规模高压力的情况下Elasticsearch会存在丢数据的情况，现在考虑使用MQ（Message Queue）进行缓冲，达到不丢数据的目的。由于对于日志收集响应速度并不是十分高，并且对日志的可靠性要求较高，最终选择Kafka来充当消息队列而非官方推荐的redis。这里着重进行kafka介绍，之后会整合EFK+kafka的应用落地记录。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
